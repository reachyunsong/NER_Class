{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\u1158286\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from numpy import nan\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from tensorflow_addons.text import crf_log_likelihood, crf_decode\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "import transformers\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import TFBertModel\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERModel(tf.keras.Model):\n",
    "   def __init__(self, bert_model, num_labels):\n",
    "       super(NERModel, self).__init__()\n",
    "       self.bert = bert_model\n",
    "       self.bilstm = Bidirectional(LSTM(128, return_sequences=True))\n",
    "       self.classifier = Dense(num_labels)\n",
    "       self.transition_params = tf.Variable(tf.random.uniform(shape=(num_labels, num_labels)))\n",
    "       \n",
    "   def call(self, inputs, training=False):\n",
    "       input_ids, attention_mask = inputs\n",
    "       bert_output = self.bert(input_ids, attention_mask=attention_mask)[0]\n",
    "       lstm_output = self.bilstm(bert_output)\n",
    "       logits = self.classifier(lstm_output)\n",
    "       return logits\n",
    "   \n",
    "   def compute_loss(self, logits, labels, seq_lengths):\n",
    "       log_likelihood, self.transition_params = crf_log_likelihood(\n",
    "           logits, labels, seq_lengths, self.transition_params\n",
    "       )\n",
    "       return -tf.reduce_mean(log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_model = TFBertModel.from_pretrained(r'C:\\Users\\u1158286\\OneDrive - IQVIA\\Desktop\\NER\\bert_model\\bert-base-uncased',from_pt = True)\n",
    "# ner_model = NERModel(bert_model,16)\n",
    "# optimizer = Adam(learning_rate=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "465785cf6d15a5a05be77e46eb1c343d845a5590712fcaa847c9c16479499c53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
